<hr><p>title: Big Data - Apache Spark</p><p>date:  2025-03-07</p><hr><hr><p>$$P(A|B)=\frac{(B|A)P(A)}{P(B)} $$</p><pre class="language-javascript"><code>hello</code></pre><h1>I. Introduction</h1><p>Spark là 1 công cụ được Apache giới thiệu nhằm tăng tốc quá trình thực thi và tính toán</p><p>Spark không phải 1 phiên bản chính sửa của Hadoop và không phụ thuộc vào hadoop vì nó có cluster management riêng. Hadoop chỉ là 1 trong những cách triển khai Spark</p><p>Spark được sử dụng theo 2 cách:</p><ul><li> <span>lưu trữ</span></li><li> <span>xử lýSpark chỉ sử dụng hadoop với mục đích lưu trữ</span></li></ul><hr><h2>Apache Spark</h2><p>Apache Spark là lightning-fast cluster computing technology (công nghệ điện toán cụm cực nhanh).</p><p>Nó dựa trên Hadoop MapReduce và mở rộng mô hình MapReduce để tính toán hiệu quả hơn, bao gồm:</p><ul><li> <span>interactive queries (truy vấn tương tác)</span></li><li> <span>stream processing (xử lý luồng)Tính năng chính:<p>In-memory cluster computing to  increases the processing speed of an application.</p><p>Điện toán cụm trong bộ nhớ giúp tăng tốc độ xử lý của ứng dụng.</p></span></li></ul><p>Spark được thiết kế để bao phủ nhiều khối lượng công việc như:</p><p>- batch applications (xử lý theo lô) <a href="#fn-1" id="ref-1" class="footnote-ref"><sup>[1]</sup></a></p><p>- iterative algorithms (thuật toán lặp) <a href="#fn-2" id="ref-2" class="footnote-ref"><sup>[2]</sup></a></p><p>- interactive queries (truy vấn tương tác) <a href="#fn-3" id="ref-3" class="footnote-ref"><sup>[3]</sup></a></p><p>- streaming (xử lý dòng dữ liệu liên tục) <a href="#fn-4" id="ref-4" class="footnote-ref"><sup>[4]</sup></a></p><hr><h2>Evolution of Apache Spark</h2><p> - Spark là 1 dự án con của Hadoop, được phát triển vào 2009 tại AMPLab, UC Berkeley<a href="#fn-5" id="ref-5" class="footnote-ref"><sup>[5]</sup></a> bởi <a href="https://en.wikipedia.org/wiki/Matei_Zaharia" title="">Matei Zaharia</a></p><ul><li> <span>Nó được open source vào năm 2010 theo <a href="https://en-m-wikipedia-org.translate.goog/wiki/BSD<i>licenses?</i>x<i>tr</i>sl=en&amp;<i>x_tr</i>tl=vi&amp;<i>x_tr</i>hl=vi&amp;<i>x_tr</i>pto=tc" title="">giấy phép BSD</a></span></li><li> <span>Nó được tặng cho Apache Software Foundation vào năm 2013</span></li><li> <span>Hiện tại Apache Spark đã trở thành dự án Apache cấp cao nhất từ ​​tháng 2 năm 2014.</span></li></ul><hr><h2>Spark built on Hadoop</h2><p>![[Pasted image 20250228172043.png]]</p><h3>1. Standalone</h3><ul><li> <span>Spark chạy trực tiếp trên HDFS mà không cần các thành phần khác của Hadoop<p>- Spark có trình quản lý tài nguyên riêng, không phục thuộc vào YARN[^5] hay Mesos<a href="#fn-6" id="ref-6" class="footnote-ref"><sup>[6]</sup></a></p></span></li><li> <span>Cấu hình đơn giản, phù hợp khi chỉ chạy Spark mà không cần tích hợp sâu vào hệ sinh thái Hadoop</span></li></ul><h3>2. Hadoop YARN</h3><ul><li> <span>Spark được triển khai trên YARN</span></li><li> <span>Spark không cần cài đặt mà có thể chạy trực tiếp trên YARN</span></li><li> <span>Giúp tích hợp Spark vào hệ sinh thái Hadoop mà không cần quyền quản trị hệ thống</span></li><li> <span>Linh hoạt hơn vì có thể chia sẻ tài nguyên với các ứng dụng Hadoop khác</span></li></ul><h3>3. Spark in MapReduce (SIMR)</h3><ul><li> <span>Spark chạy trong môi trường MapReduce của hadoop V1</span></li><li> <span>không cài đặt Spark từ đầu, có thể khởi động Spark từ giao diện dòng lệnh.</span></li><li> <span>Không yêu cầu quyền admin, nhưng hiệu suất không cao<table><thead><tr><th>Triển khai</th><th>Quản lý tài nguyên</th><th>Tích hợp với Hadoop</th><th>Hiệu suất</th><th>Quyền admin</th></tr></thead><tbody><tr><td>Standalone</td><td>trình quản lý tài nguyên riêng</td><td>Thấp</td><td>Cao</td><td>Có</td></tr><tr><td>YARN</td><td>Yarn của Hadoop</td><td>Cao</td><td>Trung bình cao</td><td>không</td></tr><tr><td>SIMR</td><td>MapReduce</td><td>Trung Bình</td><td>Thấp</td><td>Không</td></tr></tbody></table></span></li></ul><hr><h2>Components of Spark</h2><p>![[Pasted image 20250301063131.png]]</p><h3>1. Apache Spark Core</h3><ul><li> <span>Là <b>thành phần cốt lõi</b> của Spark, cung cấp khả năng <b>xử lý dữ liệu phân tán</b> và thực thi tác vụ.</span></li><li> <span>Hỗ trợ <b>tính toán trong bộ nhớ (In-Memory Computing)</b> để tăng tốc độ xử lý dữ liệu.</span></li><li> <span>Cho phép tham chiếu các tập dữ liệu từ các hệ thống lưu trữ bên ngoài như <b>HDFS, Cassandra, S3, và HBase</b>.</span></li></ul><h3>2. Spark SQL</h3><ul><li> <span>Cung cấp <b>SchemaRDD</b>, một dạng RDD mở rộng hỗ trợ dữ liệu có cấu trúc (structured data) và bán cấu trúc (semi-structured data).</span></li><li> <span>Hỗ trợ truy vấn dữ liệu bằng <b>SQL</b> hoặc <b>DataFrame API</b> giống như các hệ quản trị cơ sở dữ liệu truyền thống.</span></li><li> <span>Có thể <b>tích hợp với các hệ thống dữ liệu lớn</b> như Hive, Avro, Parquet, ORC.</span></li></ul><h3>3. Spark Streaming</h3><ul><li> <span>Hỗ trợ <b>xử lý dữ liệu thời gian thực (real-time streaming analytics)</b>.</span></li><li> <span>Dữ liệu đầu vào được xử lý dưới dạng <b>mini-batches</b>, sau đó chuyển đổi thông qua RDD.</span></li><li> <span>Có thể <b>tích hợp với Kafka, Flume, HDFS, và Sockets</b> để thu thập và xử lý luồng dữ liệu liên tục.</span></li></ul><h3>4. MLlib (Machine Learning Library)</h3><ul><li> <span>Thư viện <b>học máy phân tán (distributed machine learning)</b> được tối ưu hóa cho kiến trúc bộ nhớ của Spark.</span></li><li> <span>Cung cấp nhiều thuật toán <b>học máy phổ biến</b> như hồi quy, phân cụm, cây quyết định, SVM, PCA.</span></li><li> <span>Theo benchmark, MLlib <b>nhanh hơn gấp 9 lần</b> so với Apache Mahout (trước khi Mahout tích hợp Spark).</span></li></ul><h3>5. GraphX</h3><ul><li> <span>Một <b>hệ thống xử lý đồ thị phân tán</b> trên nền tảng Spark.</span></li><li> <span>Cung cấp API giúp biểu diễn và tính toán đồ thị với <b>Pregel API</b>.</span></li><li> <span>Hỗ trợ các <b>thuật toán đồ thị phổ biến</b> như PageRank, Connected Components, Shortest Paths,...</span></li><li> <span>Có thể <b>chuyển đổi qua lại giữa dữ liệu dạng bảng (RDD, DataFrame) và đồ thị</b> để khai thác mối quan hệ trong dữ liệu.</span></li></ul><hr><h1>RDD - Resilient Distributed Datasets</h1><h2>1. Định nghĩa</h2><ul><li> <span>RDD là tập các đối tượng bất biến (immutable) được phân tán trên nhiều nút trong cụm</span></li><li> <span>Mỗi tập dữ liệu tỏng RDD được chia thành các phân vùng logic (logical partitions), có thể được tính toán trên các nút khác nhau trong cụm</span></li><li> <span>RDD có thể chứa bất kỳ các đối tượng Python, Java hoặc Scala nào, bao gồm các lớp do người dùng định nghĩa ( user-definded classes)</span></li><li> <span>Về cơ bản, RDD là bộ sưu tập các bản ghi phân vùng chỉ đọc (read-only partitioned)</span></li><li> <span>RDD có thể được tạo thông qua các hoạt động xác định trên trên dữ liệu ổn định (stable storage) hoặc các RDD khác.</span></li><li> <span>RDD là bộ sư tập các phần tử có khả năng chịu lỗi (fault-tolerant), có thể được vận hành song song.</span></li></ul><h2>2. Tính chất của RDD</h2><ul><li> <span>Tính bất biến (Immutable): sau khi được tạo ra, RDD không thể thay đổi. Mọi thao tác biến đổi trên RDD sẽ tạo ra RDD mới .</span></li><li> <span>Tính phân tán (Distributed): Dữ liệu trong RDD được phân tán trên nhiều nút, giúp tận dụng tài nguyên và tăng hiệu suất xử lý.</span></li></ul><h2>3. Tạo RDD</h2><p>Có 2 cách để tạo ra RDD:</p><ul><li> <span>Tham chiếu đến tập dữ liệu bên ngoài: Đọc dữ liệu từ cá hệ thống lưu trữ như HDFS, <a href="https://topdev.vn/blog/tat-tan-tat-ve-apache-cassandra/#khi-qut-qua-v-cassandra" title="">Cassandra</a>, <a href="https://aws.amazon.com/vi/what-is/apache-hbase/" title="">HBase</a> hoặc từ tệp cục bộ.</span></li><li> <span>Áp dụng các phép biến đổi (transformations): Sử dụng các phép biển đổi như map, filter trên các RDD hện có thể tạo ra RDD mới.</span></li><li> <span>Spark sử dụng khái niệm RDD để chạy MapReduce nhanh hơn và hiệu quả hơn</span></li></ul><h2>4. Các phép biến đổi và hành động trên RDD</h2><ul><li> <span>Biến đổi (Transformations): là phép toán tạo ra RDD mới từ RDD hiện có(map, zfilter, flatMap). Các phép biến đổi lazy, chỉ thực thi khi hành động được gọi.</span></li><li> <span>Hành động (Actions): thực thi các phép toán và trả về kết quả cho driver program hoặc ghi ra hệ thống lưu trữ như collect, count, saveAsTextFile.</span></li></ul><h2>5. Nguyên nhân khiến RDD chạy nhanh hơn và hiệu quả hơn</h2><h3>5.1 Khi không ứng dụng RDD</h3><h4>Data sharing is slow in MapRedue(MR)</h4><ul><li> <span><b>Vấn đề:</b> Trong Hadoop MapReduce, dữ liệu phải được lưu vào <b>HDFS (Hadoop Distributed File System)</b> giữa các bước xử lý. Điều này làm cho quá trình chia sẻ dữ liệu giữa các công việc trở nên chậm và tốn nhiều tài nguyên.</span></li><li> <span><b>Nguyên nhân:</b><ul><li> <span>Sau mỗi bước <b>Map</b> hoặc <b>Reduce</b>, dữ liệu trung gian phải được ghi vào đĩa (HDFS).</span></li><li> <span>Đọc/ghi từ HDFS có độ trễ cao hơn so với truy xuất từ bộ nhớ.</span></li></ul></span></li><li> <span><b>Hệ quả:</b><ul><li> <span>Ảnh hưởng đến hiệu suất tổng thể.</span></li><li> <span>Không phù hợp với các bài toán yêu cầu tính toán lặp (iterative algorithms) hoặc truy vấn tương tác.<p>- Cả ứng dụng Iterative[^2] and Interactive<a href="#fn-7" id="ref-7" class="footnote-ref"><sup>[7]</sup></a> đều yêu cầu chia sẻ dữ liệu nhanh hơn giữa các tác vụ song song. Chia sẻ dữ liệu chậm trong MapReduce do sao chép, tuần tự hóa và IO đĩa. Về hệ thống lưu trữ, hầu hết các ứng dụng Hadoop đều dành hơn 90% thời gian để thực hiện các hoạt động đọc-ghi HDFS.</p></span></li></ul></span></li></ul><h4>Iterative Operations on MapReduce</h4><p>![[Pasted image 20250301093408.png]]</p><ul><li> <span><b>Vấn đề:</b><ul><li> <span>MapReduce không được thiết kế cho các thuật toán lặp lại.</span></li><li> <span>Sau mỗi vòng lặp, nó phải ghi dữ liệu ra HDFS và đọc lại cho vòng lặp tiếp theo.</span></li></ul></span></li></ul><ul><li> <span><b>Hệ quả:</b><ul><li> <span>Các thuật toán học máy hoặc xử lý đồ thị (như PageRank) trên Hadoop <b>rất chậm</b> so với Spark.</span></li></ul></span></li><li> <span><b>Ví dụ:</b><ul><li> <span>Nếu bạn chạy thuật toán <b>K-Means Clustering</b> trên Hadoop, mỗi vòng lặp sẽ lưu dữ liệu ra HDFS, gây lãng phí tài nguyên và thời gian.</span></li></ul></span></li></ul><h4>Intervactive operations on MapReduce</h4><p>![[Pasted image 20250302132249.png]]</p><ul><li> <span><b>Hạn chế của MapReduce:</b><ul><li> <span>Không hỗ trợ tương tác nhanh vì <b>mỗi lần chạy một truy vấn mới, nó phải đọc lại dữ liệu từ HDFS</b>.</span></li><li> <span><b>MapReduce không có cơ chế lưu trữ trong bộ nhớ</b>, mỗi thao tác mới đều phải đọc và ghi vào đĩa.</span></li></ul></span></li><li> <span><b>Hệ quả:</b><ul><li> <span>Độ trễ cao, không phù hợp cho truy vấn dữ liệu động hoặc nhiều lần.</span></li></ul></span></li><li> <span><b>Ví dụ:</b><ul><li> <span>Nếu bạn muốn đếm số từ trong một tập dữ liệu lớn, MapReduce phải đọc toàn bộ dữ liệu từ đầu mỗi lần thực thi.</span></li></ul></span></li></ul><h3>5.2 Khi úng dụng RDD</h3><h4>Data Sharing using Spark RDD</h4><ul><li> <span><b>Ưu điểm:</b><ul><li> <span>Spark hỗ trợ <b>chia sẻ dữ liệu hiệu quả hơn</b> so với Hadoop MapReduce.</span></li><li> <span>RDD có thể được <b>cache (bộ nhớ đệm)</b> trong RAM, giúp giảm thời gian đọc/ghi.</span></li></ul></span></li><li> <span><b>Lợi ích:</b><ul><li> <span>Các công việc xử lý trên cùng một tập dữ liệu có thể tái sử dụng dữ liệu mà không cần tải lại.</span></li><li> <span>Tăng tốc độ xử lý nhiều lần so với MapReduce.</span></li><li> <span>Bộ nhớ chia sẻ nhanh hơn 10 - 100 lần só mới mạng và ổ đĩa<h4>Iterative Operations on Spark RDD</h4><p>![[Pasted image 20250302133727.png]]</p></span></li></ul></span></li><li> <span><b>Spark tối ưu hóa cho các thuật toán lặp (iterative algorithms) như Machine Learning hoặc PageRank.</b></span></li><li> <span><b>Lý do:</b><ul><li> <span>RDD có thể được <b>tái sử dụng (reused)</b> trong bộ nhớ mà không cần ghi lại vào HDFS sau mỗi vòng lặp.</span></li></ul></span></li><li> <span><b>Ứng dụng:</b><ul><li> <span>Học máy (Machine Learning) với thuật toán Gradient Descent.</span></li><li> <span>Thuật toán PageRank (tính mức độ quan trọng của trang web).</span></li></ul></span></li><li> <span><b>Ví dụ:</b><ul><li> <span>Nếu thực hiện một thuật toán <b>Gradient Descent</b>, Spark có thể giữ dữ liệu trong bộ nhớ và thực hiện nhiều vòng lặp mà không cần đọc lại từ HDFS mỗi lần.</span></li></ul></span></li></ul><h4>Interactive Operations on Spark RDD</h4><p>![[Pasted image 20250302133825.png]]</p><ul><li> <span><b>Spark RDD hỗ trợ thao tác tương tác nhanh hơn so với MapReduce.</b></span></li><li> <span><b>Lý do:</b><ul><li> <span>Spark <b>lưu trữ dữ liệu trong bộ nhớ (in-memory computing)</b> thay vì đọc/ghi liên tục vào HDFS.</span></li><li> <span>Dữ liệu có thể được truy vấn lại nhiều lần mà không cần tải lại từ đầu.</span></li></ul></span></li><li> <span><b>Ứng dụng:</b><ul><li> <span>Phân tích dữ liệu theo thời gian thực.</span></li><li> <span>Truy vấn dữ liệu nhiều lần với độ trễ thấp.</span></li></ul></span></li></ul><h3>So Sánh</h3><table><thead><tr><th>Tính năng</th><th>Spark RDD</th><th>Hadoop MapReduce</th></tr></thead><tbody><tr><td>Chia sẻ dữ liệu</td><td>Lưu trong ram</td><td>Ghi vào HDFS giữa các bước</td></tr><tr><td>truy vấn tương tác</td><td>thông qua caching mà xử lý dữ liệu liên tục</td><td>đọc dữ liệu từ hdfs nhiều lần</td></tr><tr><td>Tính toán lặp</td><td>Hiệu quả cao do dữ liệu được lưu trữ trong bộ nhớ</td><td>Chậm do phải đọc ghi liên tục vào hdfs</td></tr></tbody></table><p>→ <b>Kết luận:</b> Spark vượt trội hơn MapReduce trong các ứng dụng yêu cầu xử lý nhanh và tính toán lặp lại, nhờ vào khả năng lưu trữ dữ liệu trong bộ nhớ và giảm số lần đọc/ghi vào đĩa.</p><hr><h1>Apache Spark Core Programming</h1><h2>RDD Transformations</h2><table><thead><tr><th>S.No</th><th>Transformation</th><th>Ý nghĩa</th></tr></thead><tbody><tr><td>1</td><td><code>map(func)</code></td><td>Trả về một tập dữ liệu phân tán mới bằng cách áp dụng hàm <code>func</code> lên từng phần tử của tập dữ liệu nguồn.</td></tr><tr><td>2</td><td><code>filter(func)</code></td><td>Trả về một tập dữ liệu mới bao gồm các phần tử trong tập nguồn thỏa mãn điều kiện của <code>func</code>.</td></tr><tr><td>3</td><td><code>flatMap(func)</code></td><td>Tương tự như <code>map</code>, nhưng mỗi phần tử đầu vào có thể ánh xạ thành nhiều phần tử đầu ra.</td></tr><tr><td>4</td><td><code>mapPartitions(func)</code></td><td>Tương tự như <code>map</code>, nhưng chạy riêng trên từng phân vùng (block) của RDD.</td></tr><tr><td>5</td><td><code>mapPartitionsWithIndex(func)</code></td><td>Tương tự <code>mapPartitions</code>, nhưng cung cấp thêm chỉ mục của phân vùng.</td></tr><tr><td>6</td><td><code>sample(withReplacement, fraction, seed)</code></td><td>Lấy mẫu một phần của dữ liệu với hoặc không có thay thế, sử dụng bộ sinh số ngẫu nhiên.</td></tr><tr><td>7</td><td><code>union(otherDataset)</code></td><td>Trả về một tập dữ liệu mới là hợp của tập dữ liệu nguồn và một tập dữ liệu khác.</td></tr><tr><td>8</td><td><code>intersection(otherDataset)</code></td><td>Trả về tập dữ liệu chứa các phần tử xuất hiện trong cả hai tập dữ liệu.</td></tr><tr><td>9</td><td><code>distinct([numTasks])</code></td><td>Trả về một tập dữ liệu mới chỉ chứa các phần tử duy nhất của tập nguồn.</td></tr><tr><td>10</td><td><code>groupByKey([numTasks])</code></td><td>Khi được gọi trên tập dữ liệu (K, V), nhóm các giá trị có cùng khóa vào tập (K, Iterable<v>).</v></td></tr><tr><td>11</td><td><code>reduceByKey(func, [numTasks])</code></td><td>Tương tự <code>groupByKey</code>, nhưng áp dụng hàm <code>func</code> để tổng hợp giá trị.</td></tr><tr><td>12</td><td><code>aggregateByKey(zeroValue)(seqOp, combOp, [numTasks])</code></td><td>Tổng hợp các giá trị theo khóa bằng cách sử dụng giá trị khởi tạo, giảm thiểu việc cấp phát bộ nhớ.</td></tr><tr><td>13</td><td><code>sortByKey([ascending], [numTasks])</code></td><td>Sắp xếp tập dữ liệu theo khóa theo thứ tự tăng dần hoặc giảm dần.</td></tr><tr><td>14</td><td><code>join(otherDataset, [numTasks])</code></td><td>Kết hợp hai tập dữ liệu (K, V) và (K, W) để tạo ra (K, (V, W)).</td></tr><tr><td>15</td><td><code>cogroup(otherDataset, [numTasks])</code></td><td>Nhóm nhiều tập dữ liệu có cặp khóa-giá trị.</td></tr><tr><td>16</td><td><code>cartesian(otherDataset)</code></td><td>Trả về tập dữ liệu chứa tất cả các cặp (T, U) giữa hai tập dữ liệu T và U.</td></tr><tr><td>17</td><td><code>pipe(command, [envVars])</code></td><td>Chuyển đổi từng phân vùng của RDD bằng cách sử dụng một lệnh ngoài, ví dụ như shell script.</td></tr><tr><td>18</td><td><code>coalesce(numPartitions)</code></td><td>Giảm số lượng phân vùng của RDD mà không cần phân phối lại dữ liệu.</td></tr><tr><td>19</td><td><code>repartition(numPartitions)</code></td><td>Phân phối lại dữ liệu để tăng hoặc giảm số lượng phân vùng.</td></tr><tr><td>20</td><td><code>repartitionAndSortWithinPartitions(partitioner)</code></td><td>Tương tự <code>repartition</code>, nhưng sắp xếp dữ liệu trong từng phân vùng để tối ưu hóa quá trình shuffle.</td></tr></tbody></table><hr><h2>RDD Actions</h2><table><thead><tr><th>S.No</th><th>Action</th><th>Ý nghĩa</th></tr></thead><tbody><tr><td>1</td><td><code>reduce(func)</code></td><td>Tổng hợp các phần tử trong tập dữ liệu bằng cách sử dụng hàm <code>func</code>, nhận hai đối số và trả về một kết quả.</td></tr><tr><td>2</td><td><code>collect()</code></td><td>Trả về tất cả các phần tử của tập dữ liệu dưới dạng một mảng tại chương trình điều khiển.</td></tr><tr><td>3</td><td><code>count()</code></td><td>Trả về số lượng phần tử trong tập dữ liệu.</td></tr><tr><td>4</td><td><code>first()</code></td><td>Trả về phần tử đầu tiên của tập dữ liệu.</td></tr><tr><td>5</td><td><code>take(n)</code></td><td>Trả về một mảng chứa <code>n</code> phần tử đầu tiên của tập dữ liệu.</td></tr><tr><td>6</td><td><code>takeSample(withReplacement, num, [seed])</code></td><td>Trả về một mẫu ngẫu nhiên gồm <code>num</code> phần tử từ tập dữ liệu.</td></tr><tr><td>7</td><td><code>takeOrdered(n, [ordering])</code></td><td>Trả về <code>n</code> phần tử đầu tiên theo thứ tự mặc định hoặc tùy chỉnh.</td></tr><tr><td>8</td><td><code>saveAsTextFile(path)</code></td><td>Lưu tập dữ liệu thành các tệp văn bản tại một thư mục nhất định.</td></tr><tr><td>9</td><td><code>saveAsSequenceFile(path)</code></td><td>Lưu tập dữ liệu dưới dạng tệp Hadoop SequenceFile.</td></tr><tr><td>10</td><td><code>saveAsObjectFile(path)</code></td><td>Lưu tập dữ liệu dưới dạng các đối tượng Java đã tuần tự hóa.</td></tr><tr><td>11</td><td><code>countByKey()</code></td><td>Chỉ áp dụng cho RDD chứa (K, V), trả về số lần xuất hiện của mỗi khóa dưới dạng hashmap.</td></tr><tr><td>12</td><td><code>foreach(func)</code></td><td>Chạy hàm <code>func</code> trên mỗi phần tử của tập dữ liệu, thường được sử dụng để cập nhật các hệ thống bên ngoài.</td></tr></tbody></table><hr><h2>Numeric RDD Operations in Spark</h2><p>Spark hỗ trợ các thao tác trên dữ liệu số bằng cách sử dụng các phương thức API được định nghĩa sẵn. Các phép toán này được tính toán và trả về dưới dạng một đối tượng <code>StatusCounter</code> thông qua phương thức <code>status()</code>.</p><h3>Danh sách các phương thức xử lý dữ liệu số trong RDD</h3><table><thead><tr><th>S.No</th><th>Method</th><th>Ý nghĩa</th></tr></thead><tbody><tr><td>1</td><td><code>count()</code></td><td>Trả về số lượng phần tử trong RDD.</td></tr><tr><td>2</td><td><code>mean()</code></td><td>Trả về giá trị trung bình của các phần tử trong RDD.</td></tr><tr><td>3</td><td><code>sum()</code></td><td>Tính tổng tất cả các phần tử trong RDD.</td></tr><tr><td>4</td><td><code>max()</code></td><td>Trả về giá trị lớn nhất trong RDD.</td></tr><tr><td>5</td><td><code>min()</code></td><td>Trả về giá trị nhỏ nhất trong RDD.</td></tr><tr><td>6</td><td><code>variance()</code></td><td>Tính phương sai của các phần tử trong RDD.</td></tr><tr><td>7</td><td><code>stdev()</code></td><td>Tính độ lệch chuẩn của các phần tử trong RDD.</td></tr></tbody></table><p>#LuuVinhTuong #HCMUTE</p><hr><p><a href="#fn-8" id="ref-8" class="footnote-ref"><sup>[8]</sup></a>: <b>Batch Applications (Xử lý theo lô)</b>:</p><ul><li> <span>Là cách xử lý dữ liệu theo từng khối lớn, thay vì xử lý ngay lập tức từng phần nhỏ.</span></li><li> <span>Dữ liệu được thu thập, lưu trữ rồi mới được xử lý cùng một lúc.</span></li><li> <span>Phù hợp với các tác vụ như xử lý nhật ký hệ thống, phân tích dữ liệu lớn theo chu kỳ (hàng ngày, hàng giờ).</span></li><li> <span>Ví dụ: Hệ thống tính toán doanh số cuối ngày từ dữ liệu bán hàng.</span></li></ul><p><a href="#fn-9" id="ref-9" class="footnote-ref"><sup>[9]</sup></a>: <b>Iterative Algorithms (Thuật toán lặp)</b>:</p><ul><li> <span>Là các thuật toán cần lặp đi lặp lại trên cùng một tập dữ liệu để hội tụ về kết quả tốt nhất.</span></li><li> <span>Thường dùng trong Machine Learning (Học máy) và Graph Processing (Xử lý đồ thị).</span></li><li> <span>Ví dụ: Thuật toán phân cụm K-Means hoặc thuật toán PageRank của Google.</span></li></ul><p><a href="#fn-10" id="ref-10" class="footnote-ref"><sup>[10]</sup></a>: <b>Interactive Queries (Truy vấn tương tác)</b>:</p><ul><li> <span>Cho phép người dùng gửi truy vấn và nhận kết quả gần như ngay lập tức.</span></li><li> <span>Thường được dùng trong các hệ thống phân tích dữ liệu thời gian thực, nơi người dùng muốn kiểm tra dữ liệu một cách linh hoạt.</span></li><li> <span>Ví dụ: Truy vấn SQL trên dữ liệu lớn bằng Spark SQL để tìm kiếm thông tin nhanh chóng.</span></li></ul><p><a href="#fn-11" id="ref-11" class="footnote-ref"><sup>[11]</sup></a>: <b>Streaming (Xử lý dòng dữ liệu liên tục)</b></p><ul><li> <span>Là cách xử lý dữ liệu ngay khi nó xuất hiện, thay vì đợi gom đủ thành lô lớn.</span></li><li> <span>Thích hợp cho các ứng dụng thời gian thực như giám sát giao dịch ngân hàng, phân tích lưu lượng truy cập web.</span></li><li> <span>Ví dụ: Phát hiện gian lận trong giao dịch thẻ tín dụng theo thời gian thực.</span></li></ul><p><a href="#fn-12" id="ref-12" class="footnote-ref"><sup>[12]</sup></a>:<b>AMPLab</b> (Algorithms, Machines, and People Lab) là một phòng thí nghiệm nghiên cứu tại Đại học California, Berkeley (UC Berkeley). Đây là nơi đã phát triển nhiều công nghệ quan trọng trong lĩnh vực <b>xử lý dữ liệu lớn (Big Data)</b> và <b>trí tuệ nhân tạo (AI)</b>.</p><p><a href="#fn-13" id="ref-13" class="footnote-ref"><sup>[13]</sup></a>: <i>*YARN (Yet Another Resource Negotiator) *</i> là một thành phần quản lý tài nguyên và job scheduling của Hadoop. Nó phân bổ tài nguyên (CPU, bộ nhớ) cho nhiều ứng dụng chạy trên cụm và quản lý việc thực thi của chúng một cách hiệu quả.</p><p><a href="#fn-14" id="ref-14" class="footnote-ref"><sup>[14]</sup></a>: Apache Mesos là một <b>trình quản lý tài nguyên (resource manager)</b> mã nguồn mở, giúp phân phối và quản lý tài nguyên máy tính trong các hệ thống phân tán, đặc biệt là trong các cụm máy chủ (clusters). Nó cho phép chạy nhiều ứng dụng khác nhau như <b>Apache Spark, Hadoop, Kubernetes, Docker</b> trên cùng một cụm mà không cần quản lý tài nguyên thủ công</p>